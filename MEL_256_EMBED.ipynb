{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import librosa\n",
    "import openl3\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from os.path import isfile, join\n",
    "t.cuda.set_device(8)\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = \"/raid/amana/lavish_multi_model/emotion_detection/data/raw_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_me1256(audio_file):\n",
    "    model = openl3.models.load_audio_embedding_model(input_repr=\"mel256\", content_type=\"env\",embedding_size= 512)\n",
    "    waveform, sample_rate = librosa.load(audio_file)\n",
    "    waveform = t.tensor(waveform)\n",
    "    waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    waveform /= waveform.abs().max()\n",
    "    with t.no_grad():\n",
    "        embeddings, timestamps = openl3.get_audio_embedding(\n",
    "            waveform.numpy(), model=model, hop_size=0.1,sr=16000\n",
    "        )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(audio_dir) if isfile(join(audio_dir, f))]\n",
    "data = pd.read_csv(\"/raid/amana/lavish_multi_model/emotion_detection/data/text_data.csv\")\n",
    "data['filename'] = [f'dia{a}_utt{b}' for a,b in zip(data['Dialogue_ID'],data['Utterance_ID'])]\n",
    "labels = list(data['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = []\n",
    "\n",
    "# for a,b in zip(onlyfiles,labels):\n",
    "#     x = get_dataset_from_me1256(audio_dir+\"/\"+a)\n",
    "#     dataset.append([x,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('/raid/amana/lavish_multi_model/emotion_detection/dataset_mel256.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "# train_size = int(0.85 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 5, ..., 6, 6, 6], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(dataset[:,0],dataset[:,1],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EmotionMLP(nn.Module):\n",
    "    def softmax(self,x):\n",
    "        e_x = t.exp(x - t.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(EmotionMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(512,16)\n",
    "        self.fc2 = nn.Linear(16,num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 512)\n",
    "        x = t.relu(self.fc1(x))\n",
    "        # x = F.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "model = EmotionMLP(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:07<02:14,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 2.7742611243732886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:14<02:13,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:22<02:06,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:30<02:01,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:39<02:04,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:47<01:53,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:55<01:47,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:03<01:37,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:11<01:27,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:19<01:20,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:27<01:11,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:35<01:03,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:44<00:58,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:53<00:51,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [02:01<00:42,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [02:10<00:33,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [02:17<00:24,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:25<00:16,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:32<00:07,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:40<00:00,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Training Loss: 2.7725887298583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model,X_train,Y_train,optimizer,criterion,num_epochs,device):\n",
    "    loss_arr = []\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # model.train()\n",
    "        total_loss = 0\n",
    "        for x,y in zip(X_train,Y_train):\n",
    "            x = t.tensor(x)\n",
    "            # Forward pass\n",
    "            outputs = model(x.to(device))\n",
    "            loss = criterion(outputs,t.tensor([y]).to(device)).to(device)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        loss_arr.append(total_loss/len(X_train))\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {total_loss/len(X_train)}')\n",
    "    return loss_arr\n",
    "\n",
    "num_epochs = 20\n",
    "lossarr = train(model,X_train,Y_train,optimizer,criterion,num_epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  12.61%\n"
     ]
    }
   ],
   "source": [
    "def test(model,X_test,Y_test,device):\n",
    "    acc = 0\n",
    "    def accuracy(y_true, y_pred):\n",
    "        eq = t.eq(y_true, y_pred).int()\n",
    "        return sum(eq)/len(eq)\n",
    "\n",
    "    with t.no_grad():\n",
    "        model.eval()\n",
    "        for x,y in zip(X_test,Y_test):\n",
    "            outputs = model(t.tensor(x).to(device))\n",
    "            outputs1 = outputs.detach().cpu()\n",
    "            outputs1 = outputs1.argmax(dim=1)\n",
    "            acc += accuracy(t.tensor([y]),outputs1)\n",
    "        print(f\"accuracy: {(acc/len(X_test))*100: 0.2f}%\")\n",
    "        \n",
    "test(model,X_test,Y_test,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
