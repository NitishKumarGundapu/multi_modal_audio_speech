{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import random\n",
    "import dataset_utils\n",
    "import model_utils\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=2021):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    t.manual_seed(seed)\n",
    "    t.cuda.manual_seed(seed)\n",
    "    t.cuda.manual_seed_all(seed)m\n",
    "    t.backends.cudnn.benchmark = False\n",
    "    t.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader,criterion,device):\n",
    "    \n",
    "    def accuracy(y_true, y_pred):\n",
    "        eq = t.eq(y_true, y_pred).int()\n",
    "        return sum(eq)/len(eq)\n",
    "\n",
    "    with t.no_grad():\n",
    "        model.eval()\n",
    "        for inputs,labels in test_loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            outputs1 = outputs.detach().cpu()\n",
    "            acc += accuracy(labels,outputs1)\n",
    "        print(f\"accuracy: {(acc/len(test_loader))*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(name,model):\n",
    "    t.save(model.state_dict(), f'models/{name}.pth')\n",
    "    \n",
    "def plot_graph(arr,epochs):\n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(arr,range(1,epochs+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "audio_dir = \"/raid/amana/lavish_multi_model/emotion_detection/data/raw_audio\"\n",
    "video_dir = \"/raid/amana/lavish_multi_model/emotion_detection/data/video_frames\"\n",
    "\n",
    "\n",
    "dataset = dataset_utils.AVE_dataset(audio_dir,video_dir)\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "# device = t.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = dataset.num_classes\n",
    "model = model_utils.EmotionCNN(num_classes,in_channels=10).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [03:09<28:22, 189.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 1.7259777088176036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [06:26<25:51, 193.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 1.7224296600197724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [10:29<25:12, 216.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 1.7223556829278337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [14:34<22:47, 227.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 1.7223556826590416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [18:32<19:17, 231.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 1.7223556826590416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [22:11<15:08, 227.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 1.7223556823902495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [25:53<11:16, 225.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 1.7223556818526653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [29:25<07:22, 221.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Training Loss: 1.7223556810462892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [33:09<03:41, 221.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Training Loss: 1.7223556797023287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [36:38<00:00, 219.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Training Loss: 1.722355671100982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model,train_loader,optimizer,criterion,num_epochs,device):\n",
    "    loss_arr = []\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # model.train()\n",
    "        total_loss = 0\n",
    "        for data_point in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(data_point['audio_spec'].to(device))\n",
    "            # print(outputs.item(),data_point['emotion_arr'].item())\n",
    "            loss = criterion(outputs, data_point['emotion_arr'].to(device)).to(device)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        loss_arr.append(total_loss/len(train_loader))\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {total_loss/len(train_loader)}')\n",
    "    return loss_arr\n",
    "\n",
    "num_epochs = 10\n",
    "lossarr = train(model,train_dataloader,optimizer,criterion,num_epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
